"""
å°çº¢ä¹¦é‡‡é›†å·¥å…·æµ‹è¯•ç¨‹åº
ç”¨äºæµ‹è¯•é‡‡é›†ç¨€åœŸæŠ•èµ„ç›¸å…³åšä¸»çš„å†…å®¹

ä½¿ç”¨æ–¹æ³•ï¼š
1. å…ˆä¿®æ”¹ target_user_id ä¸ºä½ è¦æµ‹è¯•çš„åšä¸»ID
2. è¿è¡Œ: python tests/test_xiaohongshu_collector.py
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tests.xiaohongshu_collector import XiaoHongShuCollector


async def test_collect_rare_earth_blogger():
    """æµ‹è¯•é‡‡é›†ç¨€åœŸæŠ•èµ„åšä¸»çš„ç¬”è®°"""
    
    # ==================== é…ç½®åŒºåŸŸ ====================
    # è¯·åœ¨è¿™é‡Œå¡«å…¥ä½ è¦æµ‹è¯•çš„åšä¸»ç”¨æˆ·ID
    # ç”¨æˆ·IDå¯ä»¥ä»åšä¸»ä¸»é¡µURLè·å–: https://www.xiaohongshu.com/user/profile/xxxx
    target_user_id = ""  # ä¾‹å¦‚: "5f3c2b1a000000000101cdef"
    
    # é‡‡é›†æ•°é‡
    max_notes = 10
    
    # æ˜¯å¦è·å–è¯¦ç»†å†…å®¹
    get_detail = True
    # =================================================
    
    if not target_user_id:
        print("âŒ è¯·å…ˆåœ¨ä»£ç ä¸­è®¾ç½® target_user_id")
        print("\nå¦‚ä½•è·å–ç”¨æˆ·IDï¼š")
        print("1. åœ¨å°çº¢ä¹¦Appæˆ–ç½‘é¡µç‰ˆæ‰¾åˆ°ç›®æ ‡åšä¸»")
        print("2. è¿›å…¥åšä¸»ä¸»é¡µï¼Œå¤åˆ¶URLä¸­ profile/ åé¢çš„éƒ¨åˆ†")
        print("3. ä¾‹å¦‚: https://www.xiaohongshu.com/user/profile/5f3c2b1a000000000101cdef")
        print("   ç”¨æˆ·IDå°±æ˜¯: 5f3c2b1a000000000101cdef")
        return
    
    print("="*60)
    print("ğŸ§ª å°çº¢ä¹¦é‡‡é›†å·¥å…·æµ‹è¯•")
    print("="*60)
    print(f"ç›®æ ‡ç”¨æˆ·ID: {target_user_id}")
    print(f"é‡‡é›†æ•°é‡: {max_notes}")
    print(f"è·å–è¯¦æƒ…: {'æ˜¯' if get_detail else 'å¦'}")
    print("="*60)
    
    async with XiaoHongShuCollector(headless=False, use_system_chrome=True) as collector:
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        is_logged_in = await collector.check_login_status()
        
        if not is_logged_in:
            print("\nâš ï¸ éœ€è¦ç™»å½•å°çº¢ä¹¦")
            print("è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•...")
            await collector.login()
        
        # è·å–ç¬”è®°åˆ—è¡¨
        print(f"\nğŸ” å¼€å§‹é‡‡é›†ç¬”è®°...")
        notes = await collector.get_user_notes(target_user_id, max_notes)
        
        if not notes:
            print("âŒ æœªè·å–åˆ°ä»»ä½•ç¬”è®°")
            return
        
        print(f"\nğŸ“Š æˆåŠŸè·å– {len(notes)} æ¡ç¬”è®°åˆ—è¡¨")
        
        # æ˜¾ç¤ºå‰å‡ æ¡ç¬”è®°çš„æ ‡é¢˜
        print("\nğŸ“„ ç¬”è®°æ ‡é¢˜é¢„è§ˆ:")
        for i, note in enumerate(notes[:5], 1):
            title = note.get('title', 'æ— æ ‡é¢˜')[:50]
            print(f"  {i}. {title}...")
        
        # å¦‚æœéœ€è¦è¯¦ç»†å†…å®¹
        if get_detail:
            print(f"\nğŸ“– æ­£åœ¨è·å– {len(notes)} æ¡ç¬”è®°çš„è¯¦ç»†å†…å®¹...")
            detailed_notes = []
            for i, note in enumerate(notes, 1):
                print(f"\n[{i}/{len(notes)}] ", end="", flush=True)
                detail = await collector.get_note_detail(note['url'])
                if detail:
                    detailed_notes.append(detail)
                    content_preview = detail.get('content', '')[:100]
                    print(f"âœ“ {content_preview}...")
                else:
                    detailed_notes.append(note)
                    print("âœ— è·å–å¤±è´¥")
                await asyncio.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            notes = detailed_notes
        
        # ä¿å­˜æ•°æ®
        filename = collector.save_to_json(notes, username=target_user_id)
        
        print("\n" + "="*60)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š å…±é‡‡é›† {len(notes)} æ¡ç¬”è®°")
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        print("="*60)
        
        return filename


async def test_search_rare_earth_keywords():
    """æµ‹è¯•åœ¨å°çº¢ä¹¦æœç´¢ç¨€åœŸç›¸å…³å…³é”®è¯"""
    
    print("="*60)
    print("ğŸ” å°çº¢ä¹¦ç¨€åœŸå…³é”®è¯æœç´¢æµ‹è¯•")
    print("="*60)
    
    keywords = ["ç¨€åœŸ", "ç¨€åœŸæŠ•èµ„", "åŒ—æ–¹ç¨€åœŸ", "é‡‘åŠ›æ°¸ç£"]
    
    async with XiaoHongShuCollector(headless=False, use_system_chrome=True) as collector:
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        is_logged_in = await collector.check_login_status()
        
        if not is_logged_in:
            print("\nâš ï¸ éœ€è¦ç™»å½•å°çº¢ä¹¦")
            await collector.login()
        
        # å°è¯•æœç´¢å…³é”®è¯
        for keyword in keywords:
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}"
            print(f"\nğŸ” æœç´¢: {keyword}")
            print(f"   URL: {search_url}")
            
            try:
                await collector.page.goto(search_url, timeout=30000)
                await asyncio.sleep(3)
                
                # è·å–æœç´¢ç»“æœæ•°é‡
                result_items = await collector.page.locator('.note-item, .search-note-item, [class*="note"]').count()
                print(f"   æ‰¾åˆ°çº¦ {result_items} æ¡ç›¸å…³ç¬”è®°")
                
            except Exception as e:
                print(f"   âš ï¸ æœç´¢å¤±è´¥: {e}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦é‡‡é›†å·¥å…·æµ‹è¯•')
    parser.add_argument('--mode', choices=['collect', 'search'], default='collect',
                       help='æµ‹è¯•æ¨¡å¼: collect=é‡‡é›†åšä¸», search=æœç´¢å…³é”®è¯')
    
    args = parser.parse_args()
    
    try:
        if args.mode == 'collect':
            asyncio.run(test_collect_rare_earth_blogger())
        else:
            asyncio.run(test_search_rare_earth_keywords())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
