## 实施计划

### 1. 修改 ffmpeg 调用路径
**文件**: `backend/voice/audio_processor.py`
- 修改 `convert_to_wav` 方法，使用项目内 ffmpeg 路径
- 修改 `validate_audio` 方法，使用项目内 ffprobe 路径
- 添加 `FFMPEG_PATH` 配置，支持相对路径调用

### 2. 创建部署脚本
**文件**: `setup_voice.py`
- 下载 ffmpeg 便携版到 `ffmpeg/bin/` 目录
- 下载 Whisper 模型（medium 版本）到 `voice/models/` 目录
- 可选：下载 Whisper.cpp 可执行文件
- 检查并创建必要的目录结构
- 验证下载的文件完整性

### 3. 配置豆包语音参数
**文件**: `.env`
- 添加豆包语音配置参数：
  ```
  DOUBAO_VOICE_APPID=3561884959
  DOUBAO_VOICE_ACCESS_TOKEN=qwpFoXXzYTxjIWRiWwAjGEGlc_PDyK-h
  DOUBAO_VOICE_SECRET_KEY=Vt-BXogJIF-BWKXO7ypzEZDaVZTwdxNM
  ```

### 4. 安装 Python 依赖
**文件**: `requirements.txt`
- 添加 `openai-whisper` 依赖
- 添加 `torch` 依赖（Whisper 的后端）

### 5. 测试语音服务
**测试步骤**:
1. 运行 `python setup_voice.py` 部署必要文件
2. 启动后端服务
3. 测试 Whisper 语音识别
4. 测试豆包语音识别
5. 验证音频格式转换功能

### 6. 集成到主应用
- 在 `main.py` 中包含语音 API 路由
- 确保启动时初始化语音服务
- 添加健康检查端点

## 技术要点

- **ffmpeg 路径**: 使用相对路径，确保跨平台兼容性
- **模型下载**: 支持断点续传，验证文件完整性
- **环境配置**: 遵循现有代码的环境变量读取方式
- **错误处理**: 完善异常处理，确保服务稳定性
- **测试覆盖**: 验证所有语音服务提供商的功能

## 预期结果

- ✅ ffmpeg 自动下载并正确配置
- ✅ Whisper 模型成功部署
- ✅ 豆包语音参数正确配置
- ✅ 语音识别功能正常工作
- ✅ 音频格式转换功能正常