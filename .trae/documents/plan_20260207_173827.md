## 豆包语音识别功能实现计划

### 问题分析
1. **前端实现错误**：
   - 当前使用Web Speech API，不是豆包或Whisper
   - 没有调用后端语音识别API
   - 识别结果为空

2. **后端集成问题**：
   - 豆包语音集成的`transcribe`方法是async的
   - 但`voice_api.py`中调用它时是同步的

3. **UI状态**：
   - 前端已有完整的UI组件（语音按钮、音频可视化、录音状态）
   - 不需要修改UI，只需要替换功能实现

### 解决方案

#### 1. 后端修复
- **修复异步调用**：
  - 修改`voice_api.py`中的`transcribe_audio`函数为async
  - 确保正确调用豆包的async transcribe方法
- **验证豆包配置**：
  - 确认APPID、ACCESS_TOKEN、SECRET_KEY配置正确
  - 测试API调用

#### 2. 前端重构
- **保留现有UI**：
  - 保留所有现有的UI组件和样式
  - 保持音频可视化功能
  - 保持录音状态显示
- **替换核心功能**：
  - 删除Web Speech API相关代码
  - 实现MediaRecorder API录音功能
  - 实现后端API调用
  - 处理响应，显示识别结果

### 实现步骤
1. **后端修复**：
   - 修改`voice_api.py`中的`transcribe_audio`函数为async
   - 确保正确调用豆包的async transcribe方法
   - 测试API接口

2. **前端重构**：
   - 删除Web Speech API相关代码
   - 实现MediaRecorder录音功能
   - 实现后端API调用
   - 保持现有UI不变

3. **集成测试**：
   - 测试完整的录音→识别→显示流程
   - 验证豆包语音识别能正常工作
   - 优化性能和用户体验

### 技术实现细节
- **前端**：
  - 使用MediaRecorder API录制音频
  - 使用Fetch API调用后端`/voice/transcribe`接口
  - 保留现有的音频可视化和UI组件

- **后端**：
  - 修改`transcribe_audio`函数为async
  - 正确处理异步的豆包API调用
  - 确保音频文件处理正确

### 预期结果
- 前端点击语音按钮开始录音
- 录音过程中显示音频可视化
- 录音结束后发送到后端
- 后端使用豆包语音API进行识别
- 前端显示识别结果
- 整个流程流畅，识别准确率高